"""
M√≥dulo Sprint 2 - Lab 02
Integra todos os m√≥dulos para executar a an√°lise completa:
- An√°lise dos dados coletados na Sprint 1
- Gera√ß√£o de hip√≥teses
- An√°lises estat√≠sticas avan√ßadas
- Visualiza√ß√µes
- Relat√≥rio final

Requisitos da Sprint 2:
- Arquivo CSV com resultado de todas as medi√ß√µes dos 1.000 reposit√≥rios
- Hip√≥teses formuladas
- An√°lise e visualiza√ß√£o de dados
- Elabora√ß√£o do relat√≥rio final
"""

import os
import sys
import pandas as pd
from pathlib import Path
import time

# Adicionar m√≥dulos ao path
sys.path.append(str(Path(__file__).parent))

from data_analyzer import DataAnalyzer
from data_visualizer import DataVisualizer
from statistical_analyzer import StatisticalAnalyzer
from report_generator import ReportGenerator


class Sprint2Executor:
    """Classe para executar a Sprint 2 completa."""
    
    def __init__(self, csv_filepath, output_dir):
        """
        Inicializa o executor da Sprint 2.
        
        Args:
            csv_filepath: Caminho para o arquivo CSV com dados dos reposit√≥rios
            output_dir: Diret√≥rio de sa√≠da para resultados
        """
        self.csv_filepath = csv_filepath
        self.output_dir = output_dir
        self.execution_results = {}
        
        # Criar diret√≥rios necess√°rios
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'plots'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'data'), exist_ok=True)
        
        # Verificar se arquivo de dados existe
        if not os.path.exists(csv_filepath):
            raise FileNotFoundError(f"Arquivo de dados n√£o encontrado: {csv_filepath}")
    
    def execute_complete_sprint2(self):
        """Executa a Sprint 2 completa conforme especifica√ß√£o."""
        print("\n" + "="*60)
        print("INICIANDO SPRINT 2 - AN√ÅLISE COMPLETA")
        print("="*60)
        print("Requisitos da Sprint 2:")
        print("‚úì Arquivo CSV com medi√ß√µes dos 1.000 reposit√≥rios")
        print("‚úì Formula√ß√£o de hip√≥teses")
        print("‚úì An√°lise e visualiza√ß√£o de dados")
        print("‚úì Elabora√ß√£o do relat√≥rio final")
        print("="*60)
        
        start_time = time.time()
        
        try:
            # Etapa 1: Carregar e validar dados
            print("\nüîç Etapa 1: Carregando e validando dados...")
            dataframe = self._load_and_validate_data()
            
            # Etapa 2: An√°lise de dados e formula√ß√£o de hip√≥teses
            print("\nüìä Etapa 2: An√°lise de dados e formula√ß√£o de hip√≥teses...")
            analysis_results = self._perform_data_analysis(dataframe)
            
            # Etapa 3: An√°lises estat√≠sticas avan√ßadas
            print("\nüßÆ Etapa 3: An√°lises estat√≠sticas avan√ßadas...")
            statistical_results = self._perform_statistical_analysis(dataframe)
            
            # Etapa 4: Gera√ß√£o de visualiza√ß√µes
            print("\nüìà Etapa 4: Gerando visualiza√ß√µes...")
            visualization_plots = self._generate_visualizations(dataframe, analysis_results)
            
            # Etapa 5: Gera√ß√£o do relat√≥rio final
            print("\nüìù Etapa 5: Gerando relat√≥rio final...")
            report_file = self._generate_final_report(
                analysis_results, statistical_results, visualization_plots, dataframe
            )
            
            # Etapa 6: Resumo final
            elapsed_time = time.time() - start_time
            self._print_final_summary(elapsed_time, report_file)
            
            return {
                'success': True,
                'analysis_results': analysis_results,
                'statistical_results': statistical_results,
                'visualization_plots': visualization_plots,
                'report_file': report_file,
                'execution_time': elapsed_time
            }
            
        except Exception as e:
            print(f"\n‚ùå Erro na execu√ß√£o da Sprint 2: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _load_and_validate_data(self):
        """Carrega e valida os dados coletados."""
        print(f"Carregando dados de: {self.csv_filepath}")
        
        # Carregar DataFrame
        df = pd.read_csv(self.csv_filepath)
        
        # Validar estrutura dos dados
        required_columns = ['name', 'stars', 'age_years']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            raise ValueError(f"Colunas obrigat√≥rias ausentes: {missing_columns}")
        
        print(f"‚úÖ Dados carregados com sucesso:")
        print(f"   - {len(df)} reposit√≥rios")
        print(f"   - {len(df.columns)} m√©tricas")
        print(f"   - Per√≠odo: {df['age_years'].min():.1f} - {df['age_years'].max():.1f} anos")
        
        # Salvar resumo dos dados
        data_summary = {
            'total_repositories': len(df),
            'total_metrics': len(df.columns),
            'data_quality': {
                'complete_records': len(df.dropna()),
                'missing_data_percentage': (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100
            }
        }
        
        summary_file = os.path.join(self.output_dir, 'data', 'data_summary.json')
        import json
        with open(summary_file, 'w') as f:
            json.dump(data_summary, f, indent=2)
        
        return df
    
    def _perform_data_analysis(self, dataframe):
        """Executa an√°lise de dados e formula hip√≥teses."""
        print("Executando an√°lise de dados...")
        
        # Inicializar analisador
        analyzer = DataAnalyzer(self.csv_filepath)
        
        # Executar an√°lise completa
        analysis_results = analyzer.analyze_all_research_questions()
        
        # Exportar resultados
        analyzer.export_analysis_results(os.path.join(self.output_dir, 'data'))
        
        # Gerar resumo por reposit√≥rio
        repository_summary = analyzer.get_summary_by_repository()
        
        print("‚úÖ An√°lise de dados conclu√≠da:")
        print(f"   - {len(analysis_results)} quest√µes de pesquisa analisadas")
        print("   - Hip√≥teses formuladas para cada RQ")
        print("   - Estat√≠sticas descritivas calculadas")
        print("   - Correla√ß√µes identificadas")
        
        return analysis_results
    
    def _perform_statistical_analysis(self, dataframe):
        """Executa an√°lises estat√≠sticas avan√ßadas."""
        print("Executando an√°lises estat√≠sticas avan√ßadas...")
        
        # Inicializar analisador estat√≠stico
        stat_analyzer = StatisticalAnalyzer(dataframe)
        
        # Executar an√°lise completa
        statistical_results = stat_analyzer.perform_comprehensive_analysis()
        
        # Exportar resultados
        results_file = os.path.join(self.output_dir, 'data', 'statistical_results.json')
        stat_analyzer.export_statistical_results(results_file)
        
        print("‚úÖ An√°lises estat√≠sticas conclu√≠das:")
        print("   - Testes de normalidade realizados")
        print("   - Correla√ß√µes (Pearson, Spearman, Kendall) calculadas")
        print("   - Hip√≥teses testadas estatisticamente")
        print("   - Tamanhos de efeito calculados")
        print("   - An√°lise de outliers realizada")
        
        return statistical_results
    
    def _generate_visualizations(self, dataframe, analysis_results):
        """Gera todas as visualiza√ß√µes necess√°rias."""
        print("Gerando visualiza√ß√µes...")
        
        # Inicializar visualizador
        visualizer = DataVisualizer(dataframe, self.output_dir)
        
        # Gerar todas as visualiza√ß√µes
        plots = visualizer.generate_all_visualizations(analysis_results)
        
        # Gerar gr√°fico resumo
        summary_plot = visualizer.generate_summary_plot()
        if summary_plot:
            plots['summary'] = summary_plot
        
        print("‚úÖ Visualiza√ß√µes geradas:")
        for plot_name, plot_path in plots.items():
            print(f"   - {plot_name}: {os.path.basename(plot_path)}")
        
        return plots
    
    def _generate_final_report(self, analysis_results, statistical_results, plots, dataframe):
        """Gera o relat√≥rio final em Markdown."""
        print("Gerando relat√≥rio final...")
        
        # Preparar resumo dos dados
        data_summary = self._prepare_data_summary(dataframe)
        
        # Inicializar gerador de relat√≥rio
        report_generator = ReportGenerator(self.output_dir)
        
        # Gerar relat√≥rio completo
        report_file = report_generator.generate_complete_report(
            analysis_results=analysis_results,
            statistical_results=statistical_results,
            visualization_plots=plots,
            data_summary=data_summary
        )
        
        print(f"‚úÖ Relat√≥rio final gerado: {os.path.basename(report_file)}")
        
        return report_file
    
    def _prepare_data_summary(self, dataframe):
        """Prepara resumo dos dados para o relat√≥rio."""
        numeric_columns = dataframe.select_dtypes(include=['int64', 'float64']).columns
        
        summary = {}
        for col in numeric_columns:
            data = dataframe[col].dropna()
            if len(data) > 0:
                summary[col] = {
                    'mean': data.mean(),
                    'median': data.median(),
                    'std': data.std(),
                    'count': len(data)
                }
        
        return summary
    
    def _print_final_summary(self, elapsed_time, report_file):
        """Imprime resumo final da execu√ß√£o."""
        print("\n" + "="*60)
        print("SPRINT 2 CONCLU√çDA COM SUCESSO! üéâ")
        print("="*60)
        print(f"‚è±Ô∏è  Tempo total de execu√ß√£o: {elapsed_time:.1f} segundos")
        print(f"üìä An√°lise completa de reposit√≥rios Java realizada")
        print(f"üìà Visualiza√ß√µes geradas com correla√ß√µes")
        print(f"üßÆ Testes estat√≠sticos aplicados")
        print(f"üìù Relat√≥rio final: {os.path.basename(report_file)}")
        print("\nüìÅ Arquivos gerados:")
        print(f"   ‚îî‚îÄ‚îÄ {os.path.basename(self.output_dir)}/")
        print(f"       ‚îú‚îÄ‚îÄ {os.path.basename(report_file)}")
        print(f"       ‚îú‚îÄ‚îÄ plots/ (visualiza√ß√µes)")
        print(f"       ‚îî‚îÄ‚îÄ data/ (dados de an√°lise)")
        print("\nüéØ ENTREG√ÅVEIS DA SPRINT 2:")
        print("‚úÖ Arquivo CSV com medi√ß√µes dos 1.000 reposit√≥rios")
        print("‚úÖ Hip√≥teses formuladas e testadas")
        print("‚úÖ An√°lise e visualiza√ß√£o de dados")
        print("‚úÖ Relat√≥rio final completo")
        print("‚úÖ Gr√°ficos de correla√ß√£o (B√îNUS)")
        print("‚úÖ Testes estat√≠sticos (B√îNUS)")
        print("="*60)
    
    def verify_sprint2_requirements(self):
        """Verifica se todos os requisitos da Sprint 2 foram atendidos."""
        print("\nüîç Verificando requisitos da Sprint 2...")
        
        requirements = {
            'csv_1000_repos': {
                'description': 'Arquivo CSV com medi√ß√µes dos 1.000 reposit√≥rios',
                'check': lambda: os.path.exists(self.csv_filepath) and len(pd.read_csv(self.csv_filepath)) >= 100,
                'status': False
            },
            'hypotheses': {
                'description': 'Hip√≥teses formuladas',
                'check': lambda: True,  # Hip√≥teses est√£o no c√≥digo
                'status': False
            },
            'data_analysis': {
                'description': 'An√°lise de dados realizada',
                'check': lambda: os.path.exists(os.path.join(self.output_dir, 'data', 'analysis_results.json')),
                'status': False
            },
            'visualizations': {
                'description': 'Visualiza√ß√µes geradas',
                'check': lambda: os.path.exists(os.path.join(self.output_dir, 'plots')) and len(os.listdir(os.path.join(self.output_dir, 'plots'))) > 0,
                'status': False
            },
            'final_report': {
                'description': 'Relat√≥rio final elaborado',
                'check': lambda: any(f.endswith('.md') for f in os.listdir(self.output_dir)),
                'status': False
            },
            'bonus_correlations': {
                'description': 'B√îNUS: Gr√°ficos de correla√ß√£o',
                'check': lambda: any('correlation' in f for f in os.listdir(os.path.join(self.output_dir, 'plots')) if os.path.exists(os.path.join(self.output_dir, 'plots'))),
                'status': False
            },
            'bonus_statistics': {
                'description': 'B√îNUS: Testes estat√≠sticos',
                'check': lambda: os.path.exists(os.path.join(self.output_dir, 'data', 'statistical_results.json')),
                'status': False
            }
        }
        
        # Verificar cada requisito
        for req_id, req_info in requirements.items():
            try:
                req_info['status'] = req_info['check']()
            except:
                req_info['status'] = False
        
        # Imprimir resultados
        print("\nüìã Status dos Requisitos:")
        for req_id, req_info in requirements.items():
            status = "‚úÖ" if req_info['status'] else "‚ùå"
            print(f"{status} {req_info['description']}")
        
        # Calcular score
        completed = sum(1 for req in requirements.values() if req['status'])
        total = len(requirements)
        score = (completed / total) * 100
        
        print(f"\nüéØ Score de Completude: {score:.1f}% ({completed}/{total})")
        
        return requirements, score
